{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X_train, y_train = transformed_featured_train_set.drop('Churn', axis=1), transformed_featured_train_set['Churn']  # Extract training features and labels\n",
    "    X_val, y_val = transformed_featured_val_set.drop('Churn', axis=1), transformed_featured_val_set['Churn']  # Extract validation features and labels\n",
    "    \n",
    "    # Sample indices for hyperparameters from different models\n",
    "    lgb_study = drop_unnecessary_columns(featured_lgb_study.copy())  # Prepare LightGBM study data\n",
    "    xgb_study = drop_unnecessary_columns(featured_xgb_study.copy())  # Prepare XGBoost study data\n",
    "    cat_study = drop_unnecessary_columns(featured_cat_study.copy())  # Prepare CatBoost study data\n",
    "    nn_study = drop_unnecessary_columns(featured_nn_study.copy())  # Prepare Neural Network study data\n",
    "    \n",
    "    lgb_idx = trial.suggest_int('lgb_idx', 0, len(lgb_study) - 1)  # Sample index for LightGBM hyperparameters\n",
    "    xgb_idx = trial.suggest_int('xgb_idx', 0, len(xgb_study) - 1)  # Sample index for XGBoost hyperparameters\n",
    "    cat_idx = trial.suggest_int('cat_idx', 0, len(cat_study) - 1)  # Sample index for CatBoost hyperparameters\n",
    "    nn_idx = trial.suggest_int('nn_idx', 0, len(nn_study) - 1)  # Sample index for Neural Network hyperparameters\n",
    "    \n",
    "    # Fetch hyperparameters and clean them\n",
    "    lgb_params = clean_hyperparameters(lgb_study.iloc[lgb_idx].to_dict())  # Get LightGBM parameters\n",
    "    xgb_params = clean_hyperparameters(xgb_study.iloc[xgb_idx].to_dict())  # Get XGBoost parameters\n",
    "    cat_params = clean_hyperparameters(cat_study.iloc[cat_idx].to_dict())  # Get CatBoost parameters\n",
    "    nn_params = clean_hyperparameters(nn_study.iloc[nn_idx].to_dict())  # Get Neural Network parameters\n",
    "    \n",
    "    # Set additional fixed hyperparameters\n",
    "    lgb_params['verbose'] = -1  # Silence LightGBM output\n",
    "    xgb_params['verbose'] = 0  # Silence XGBoost output\n",
    "    cat_params['early_stopping_rounds'] = 3000  # Set early stopping rounds for CatBoost\n",
    "    cat_params['iterations'] = 200  # Set number of iterations for CatBoost\n",
    "\n",
    "    # Weights for the voting classifier\n",
    "    lgb_weight = trial.suggest_float('lgb_weight', 0.1, 1.0)  # Suggest weight for LightGBM\n",
    "    xgb_weight = trial.suggest_float('xgb_weight', 0.1, 1.0)  # Suggest weight for XGBoost\n",
    "    cat_weight = trial.suggest_float('cat_weight', 0.1, 1.0)  # Suggest weight for CatBoost\n",
    "    nn_weight = trial.suggest_float('nn_weight', 0.1, 1.0)  # Suggest weight for Neural Network\n",
    "\n",
    "    weights = {\n",
    "        'lgb': lgb_weight,\n",
    "        'xgb': xgb_weight,\n",
    "        'cat': cat_weight,\n",
    "        'nn': nn_weight\n",
    "    }  # Store weights in a dictionary\n",
    "    \n",
    "    #Let’s give these models some workout time. First up, LightGBM. \n",
    "    #It's like the gym but for data—let’s see if it can lift those predictions high!\n",
    "    \n",
    "    # Train and predict with LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)  # Prepare LightGBM dataset\n",
    "    lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)  # Train LightGBM model\n",
    "    lgb_preds = lgb_model.predict(X_val)  # Predict on validation set with LightGBM\n",
    "    \n",
    "    #Phew, LightGBM is done. Now let’s see if XGBoost can boost our mood... or just our predictions!\"\n",
    "    \n",
    "    # Train and predict with XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)  # Initialize XGBoost model with parameters\n",
    "    xgb_model.fit(X_train, y_train)  # Train XGBoost model\n",
    "    xgb_preds = xgb_model.predict_proba(X_val)[:, 1]  # Predict on validation set with XGBoost and get probabilities\n",
    "\n",
    "    # Train and predict with CatBoost\n",
    "    cat_model = cb.CatBoostClassifier(**cat_params, verbose=0)  # Initialize CatBoost model with parameters\n",
    "    cat_model.fit(X_train, y_train)  # Train CatBoost model\n",
    "    cat_preds = cat_model.predict_proba(X_val)[:, 1]  # Predict on validation set with CatBoost and get probabilities\n",
    "\n",
    "    # Train and predict with Neural Network using TensorFlow/Keras\n",
    "    nn_model = create_nn_model(nn_params, transformed_featured_train_set.shape[1] - 1)  # Create Neural Network model\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=int(nn_params['batch_size']), verbose=0)  # Train Neural Network model\n",
    "    nn_preds = nn_model.predict(transformed_featured_val_set.drop('Churn', axis=1)).ravel()  # Predict on validation set with Neural Network\n",
    "\n",
    "    # Combine predictions using weighted soft voting\n",
    "    predictions = {\n",
    "        'lgb': lgb_preds,\n",
    "        'xgb': xgb_preds,\n",
    "        'cat': cat_preds,\n",
    "        'nn': nn_preds\n",
    "    }  # Store predictions in a dictionary\n",
    "    combined_preds = weighted_voting(predictions, weights)  # Perform weighted voting to combine predictions\n",
    "    preds_digits = [1 if pred >= 0.4 else 0 for pred in combined_preds]  # Convert probabilities to binary predictions with a threshold of 0.4\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_val, combined_preds)  # Calculate ROC AUC score\n",
    "    f1 = f1_score(y_val, preds_digits)  # Calculate F1 score\n",
    "    recall = recall_score(y_val, preds_digits)  # Calculate recall score\n",
    "    accuracy = accuracy_score(y_val, preds_digits)  # Calculate accuracy score\n",
    "    weighted_recall = 0.65 * recall + 0.35 * f1  # Calculate weighted recall combining recall and F1 score\n",
    "    prec = precision_score(y_val, preds_digits)  # Calculate precision score\n",
    "    \n",
    "    # Store metrics as trial user attributes\n",
    "    trial.set_user_attr('roc', roc_auc)  # Store ROC AUC score in the study\n",
    "    trial.set_user_attr('f1', f1)  # Store F1 score in the study object\n",
    "    trial.set_user_attr('accuracy', accuracy)  # Store accuracy score\n",
    "    trial.set_user_attr('recall', recall)  # Store recall score\n",
    "    trial.set_user_attr('precision', prec)  # Store precision score\n",
    "    \n",
    "    return weighted_recall  # Return weighted recall as the objective value for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ensemble_trials = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_ensemble_trials:\n",
    "    # Create Optuna study and optimize\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=25 , n_jobs =-1)\n",
    "\n",
    "    # Best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(f'Best metric: {best_trial.value}')\n",
    "    print('Best hyperparameters and weights:', best_trial.params)\n",
    "    trials = study.trials\n",
    "\n",
    "    # Extract trial data\n",
    "    data = {\n",
    "        'trial_number': [trial.number for trial in trials],\n",
    "        'value': [trial.value for trial in trials],\n",
    "        'params': [trial.params for trial in trials],\n",
    "        'datetime_start': [trial.datetime_start for trial in trials],\n",
    "        'datetime_complete': [trial.datetime_complete for trial in trials],\n",
    "        'f1': [trial.user_attrs.get('f1', None) for trial in trials],\n",
    "        'accuracy': [trial.user_attrs.get('accuracy', None) for trial in trials],\n",
    "        'roc': [trial.user_attrs.get('roc', None) for trial in trials],\n",
    "        'recall': [trial.user_attrs.get('recall', None) for trial in trials],\n",
    "        'precision': [trial.user_attrs.get('precision', None) for trial in trials]\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    ensemble_results_df = pd.DataFrame(data)\n",
    "    \n",
    "else:\n",
    "    ensemble_results_df = pd.read_csv(r\"../data/processed/ensemble_study.csv\")\n",
    "    ensemble_results_df = ensemble_results_df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's performance which has highest weighted recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['value'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                        22\n",
       "value                                                         0.633703\n",
       "params               {'lgb_idx': 88, 'xgb_idx': 86, 'nn_idx': 40, '...\n",
       "datetime_start                              2024-08-04 06:40:54.247899\n",
       "datetime_complete                           2024-08-04 06:41:05.081042\n",
       "f1                                                            0.616702\n",
       "accuracy                                                      0.787915\n",
       "roc                                                           0.836247\n",
       "recall                                                        0.642857\n",
       "precision                                                     0.592593\n",
       "Name: 22, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model's performance which has highest recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['recall'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                        18\n",
       "value                                                         0.565997\n",
       "params               {'lgb_idx': 54, 'xgb_idx': 17, 'nn_idx': 37, '...\n",
       "datetime_start                              2024-08-04 06:39:18.898603\n",
       "datetime_complete                           2024-08-04 06:39:50.271158\n",
       "f1                                                            0.589074\n",
       "accuracy                                                      0.795024\n",
       "roc                                                           0.828571\n",
       "recall                                                        0.553571\n",
       "precision                                                     0.629442\n",
       "Name: 18, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model's performance which has highest precision\n",
    "ensemble_results_df.iloc[ensemble_results_df['precision'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.7596 - loss: 0.5024 - val_AUC: 0.8363 - val_loss: 0.4315\n",
      "Epoch 2/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8304 - loss: 0.4374 - val_AUC: 0.8388 - val_loss: 0.4289\n",
      "Epoch 3/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8331 - loss: 0.4351 - val_AUC: 0.8373 - val_loss: 0.4281\n",
      "Epoch 4/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8401 - loss: 0.4273 - val_AUC: 0.8388 - val_loss: 0.4259\n",
      "Epoch 5/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.8500 - loss: 0.4151 - val_AUC: 0.8387 - val_loss: 0.4258\n",
      "Epoch 6/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8476 - loss: 0.4168 - val_AUC: 0.8378 - val_loss: 0.4272\n",
      "Epoch 7/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8522 - loss: 0.4117 - val_AUC: 0.8383 - val_loss: 0.4269\n",
      "Epoch 8/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8508 - loss: 0.4141 - val_AUC: 0.8369 - val_loss: 0.4285\n",
      "Epoch 9/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.8534 - loss: 0.4105 - val_AUC: 0.8378 - val_loss: 0.4274\n",
      "Epoch 10/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8620 - loss: 0.3987 - val_AUC: 0.8375 - val_loss: 0.4282\n",
      "Epoch 11/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8617 - loss: 0.3988 - val_AUC: 0.8366 - val_loss: 0.4287\n",
      "Epoch 12/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8596 - loss: 0.4024 - val_AUC: 0.8372 - val_loss: 0.4267\n",
      "Epoch 13/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8609 - loss: 0.4008 - val_AUC: 0.8361 - val_loss: 0.4290\n",
      "Epoch 14/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8704 - loss: 0.3887 - val_AUC: 0.8364 - val_loss: 0.4281\n",
      "Epoch 15/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8690 - loss: 0.3907 - val_AUC: 0.8365 - val_loss: 0.4289\n",
      "Epoch 16/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8734 - loss: 0.3840 - val_AUC: 0.8352 - val_loss: 0.4298\n",
      "Epoch 17/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8738 - loss: 0.3853 - val_AUC: 0.8333 - val_loss: 0.4305\n",
      "Epoch 18/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8746 - loss: 0.3827 - val_AUC: 0.8328 - val_loss: 0.4325\n",
      "Epoch 19/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8772 - loss: 0.3803 - val_AUC: 0.8321 - val_loss: 0.4320\n",
      "Epoch 20/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8793 - loss: 0.3781 - val_AUC: 0.8337 - val_loss: 0.4326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a3999a0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_model = create_nn_model(clean_hyperparameters(featured_nn_study.iloc[87].to_dict()),input_shape=transformed_featured_train_set.drop(columns='Churn').shape[1])\n",
    "ann_model.fit(transformed_featured_final_train_set.drop(columns='Churn'),transformed_featured_final_train_set['Churn'],epochs=20,validation_data=(transformed_featured_test_set.drop(columns='Churn'),transformed_featured_test_set['Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc score is:- 0.8336215063337664\n",
      "recall score is :- 0.7112299465240641\n",
      "precision score is:- 0.564755838641189\n"
     ]
    }
   ],
   "source": [
    "#let's see final model's performance\n",
    "preds = ann_model.predict(transformed_featured_test_set.drop(columns='Churn'))\n",
    "print('roc_auc score is:-',roc_auc_score(transformed_featured_test_set['Churn'],preds))\n",
    "preds_digits = [1 if pred >= 0.4 else 0 for pred in preds]\n",
    "print('recall score is :-',recall_score(transformed_featured_test_set['Churn'],preds_digits))\n",
    "print('precision score is:-',precision_score(transformed_featured_test_set['Churn'],preds_digits))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
