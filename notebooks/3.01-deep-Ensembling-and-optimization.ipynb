{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,f1_score,precision_score\n",
    "from optimization.optimize_ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_featured_train_set = pd.read_csv(r\"../data/processed/transformed_featured_train_set.csv\").drop(columns=\"Unnamed: 0\")\n",
    "transformed_featured_val_set = pd.read_csv(r\"../data/processed/transformed_featured_val_set.csv\").drop(columns=\"Unnamed: 0\")\n",
    "transformed_featured_test_set = pd.read_csv(r\"../data/processed/transformed_featured_test_set.csv\").drop(columns=\"Unnamed: 0\")\n",
    "transformed_featured_final_train_set = pd.read_csv(r\"../data/processed/transformed_featured_final_train_set.csv\").drop(columns=\"Unnamed: 0\")\n",
    "lgb_featured_study = pd.read_csv(r\"../data/processed/lgb_featured_study.csv\").drop(columns=\"Unnamed: 0\")\n",
    "xgb_featured_study = pd.read_csv(r\"../data/processed/xgb_featured_study.csv\").drop(columns=\"Unnamed: 0\")\n",
    "catboost_featured_study = pd.read_csv(r\"../data/processed/catboost_featured_study.csv\").drop(columns=\"Unnamed: 0\")\n",
    "nn_featured_study = pd.read_csv(r\"../data/processed/nn_featured_study.csv\").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    X_train, y_train = transformed_featured_train_set.drop('Churn', axis=1), transformed_featured_train_set['Churn']  # Extract training features and labels\n",
    "    X_val, y_val = transformed_featured_val_set.drop('Churn', axis=1), transformed_featured_val_set['Churn']  # Extract validation features and labels\n",
    "    \n",
    "    # Sample indices for hyperparameters from different models\n",
    "    lgb_study = drop_unnessesary_columns(lgb_featured_study.copy())  # Prepare LightGBM study data\n",
    "    xgb_study = drop_unnessesary_columns(xgb_featured_study.copy())  # Prepare XGBoost study data\n",
    "    cat_study = drop_unnessesary_columns(catboost_featured_study.copy())  # Prepare CatBoost study data\n",
    "    nn_study = drop_unnessesary_columns(nn_featured_study.copy())  # Prepare Neural Network study data\n",
    "    \n",
    "    lgb_idx = trial.suggest_int('lgb_idx', 0, len(lgb_study) - 1)  # Sample index for LightGBM hyperparameters\n",
    "    xgb_idx = trial.suggest_int('xgb_idx', 0, len(xgb_study) - 1)  # Sample index for XGBoost hyperparameters\n",
    "    cat_idx = trial.suggest_int('cat_idx', 0, len(cat_study) - 1)  # Sample index for CatBoost hyperparameters\n",
    "    nn_idx = trial.suggest_int('nn_idx', 0, len(nn_study) - 1)  # Sample index for Neural Network hyperparameters\n",
    "    \n",
    "    # Fetch hyperparameters and clean them\n",
    "    lgb_params = clean_hyperparameters(lgb_study.iloc[lgb_idx].to_dict())  # Get LightGBM parameters\n",
    "    xgb_params = clean_hyperparameters(xgb_study.iloc[xgb_idx].to_dict())  # Get XGBoost parameters\n",
    "    cat_params = clean_hyperparameters(cat_study.iloc[cat_idx].to_dict())  # Get CatBoost parameters\n",
    "    nn_params = clean_hyperparameters(nn_study.iloc[nn_idx].to_dict())  # Get Neural Network parameters\n",
    "    \n",
    "    # Set additional fixed hyperparameters\n",
    "    lgb_params['verbose'] = -1  # Silence LightGBM output\n",
    "    xgb_params['verbose'] = 0  # Silence XGBoost output\n",
    "    cat_params['early_stopping_rounds'] = 3000  # Set early stopping rounds for CatBoost\n",
    "    cat_params['iterations'] = 200  # Set number of iterations for CatBoost\n",
    "\n",
    "    # Weights for the voting classifier\n",
    "    lgb_weight = trial.suggest_float('lgb_weight', 0.1, 1.0)  # Suggest weight for LightGBM\n",
    "    xgb_weight = trial.suggest_float('xgb_weight', 0.1, 1.0)  # Suggest weight for XGBoost\n",
    "    cat_weight = trial.suggest_float('cat_weight', 0.1, 1.0)  # Suggest weight for CatBoost\n",
    "    nn_weight = trial.suggest_float('nn_weight', 0.1, 1.0)  # Suggest weight for Neural Network\n",
    "\n",
    "    weights = {\n",
    "        'lgb': lgb_weight,\n",
    "        'xgb': xgb_weight,\n",
    "        'cat': cat_weight,\n",
    "        'nn': nn_weight\n",
    "    }  # Store weights in a dictionary\n",
    "    \n",
    "    #Let’s give these models some workout time. First up, LightGBM. \n",
    "    #It's like the gym but for data—let’s see if it can lift those predictions high!\n",
    "    \n",
    "    # Train and predict with LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)  # Prepare LightGBM dataset\n",
    "    lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)  # Train LightGBM model\n",
    "    lgb_preds = lgb_model.predict(X_val)  # Predict on validation set with LightGBM\n",
    "    \n",
    "    #Phew, LightGBM is done. Now let’s see if XGBoost can boost our mood... or just our predictions!\"\n",
    "    \n",
    "    # Train and predict with XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)  # Initialize XGBoost model with parameters\n",
    "    xgb_model.fit(X_train, y_train)  # Train XGBoost model\n",
    "    xgb_preds = xgb_model.predict_proba(X_val)[:, 1]  # Predict on validation set with XGBoost and get probabilities\n",
    "\n",
    "    # Train and predict with CatBoost\n",
    "    cat_model = cb.CatBoostClassifier(**cat_params, verbose=0)  # Initialize CatBoost model with parameters\n",
    "    cat_model.fit(X_train, y_train)  # Train CatBoost model\n",
    "    cat_preds = cat_model.predict_proba(X_val)[:, 1]  # Predict on validation set with CatBoost and get probabilities\n",
    "\n",
    "    # Train and predict with Neural Network using TensorFlow/Keras\n",
    "    nn_model = create_nn_model(nn_params, transformed_featured_train_set.shape[1] - 1)  # Create Neural Network model\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=int(nn_params['batch_size']), verbose=0)  # Train Neural Network model\n",
    "    nn_preds = nn_model.predict(transformed_featured_val_set.drop('Churn', axis=1)).ravel()  # Predict on validation set with Neural Network\n",
    "\n",
    "    # Combine predictions using weighted soft voting\n",
    "    predictions = {\n",
    "        'lgb': lgb_preds,\n",
    "        'xgb': xgb_preds,\n",
    "        'cat': cat_preds,\n",
    "        'nn': nn_preds\n",
    "    }  # Store predictions in a dictionary\n",
    "    combined_preds = weighted_voting(predictions, weights)  # Perform weighted voting to combine predictions\n",
    "    preds_digits = [1 if pred >= 0.4 else 0 for pred in combined_preds]  # Convert probabilities to binary predictions with a threshold of 0.4\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_val, combined_preds)  # Calculate ROC AUC score\n",
    "    f1 = f1_score(y_val, preds_digits)  # Calculate F1 score\n",
    "    recall = recall_score(y_val, preds_digits)  # Calculate recall score\n",
    "    accuracy = accuracy_score(y_val, preds_digits)  # Calculate accuracy score\n",
    "    weighted_recall = 0.65 * recall + 0.35 * f1  # Calculate weighted recall combining recall and F1 score\n",
    "    prec = precision_score(y_val, preds_digits)  # Calculate precision score\n",
    "    \n",
    "    # Store metrics as trial user attributes\n",
    "    trial.set_user_attr('roc', roc_auc)  # Store ROC AUC score in the study\n",
    "    trial.set_user_attr('f1', f1)  # Store F1 score in the study object\n",
    "    trial.set_user_attr('accuracy', accuracy)  # Store accuracy score\n",
    "    trial.set_user_attr('recall', recall)  # Store recall score\n",
    "    trial.set_user_attr('precision', prec)  # Store precision score\n",
    "    \n",
    "    return weighted_recall  # Return weighted recall as the objective value for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ensemble_trials = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:31:56,538] A new study created in memory with name: no-name-0ccd6f9f-d607-43c2-a064-ac19ff9dbc40\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:32:52,130] Trial 1 finished with value: 0.4530418297455969 and parameters: {'lgb_idx': 34, 'xgb_idx': 4, 'cat_idx': 79, 'nn_idx': 23, 'lgb_weight': 0.14430690847063413, 'xgb_weight': 0.19893934753510428, 'cat_weight': 0.6449578457217432, 'nn_weight': 0.22432652495515237}. Best is trial 1 with value: 0.4530418297455969.\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:33:07,148] Trial 4 finished with value: 0.5272149725274725 and parameters: {'lgb_idx': 88, 'xgb_idx': 29, 'cat_idx': 27, 'nn_idx': 27, 'lgb_weight': 0.8682825141787712, 'xgb_weight': 0.1829775645894997, 'cat_weight': 0.6873994836835665, 'nn_weight': 0.7328736277672686}. Best is trial 4 with value: 0.5272149725274725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:33:11,558] Trial 2 finished with value: 0.5619196428571429 and parameters: {'lgb_idx': 75, 'xgb_idx': 20, 'cat_idx': 70, 'nn_idx': 68, 'lgb_weight': 0.8638740862850363, 'xgb_weight': 0.7853652920061945, 'cat_weight': 0.6638401876054422, 'nn_weight': 0.6302199777678311}. Best is trial 2 with value: 0.5619196428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:33:18,459] Trial 0 finished with value: 0.6274205524205525 and parameters: {'lgb_idx': 95, 'xgb_idx': 74, 'cat_idx': 24, 'nn_idx': 87, 'lgb_weight': 0.7650223732630748, 'xgb_weight': 0.41515159469352747, 'cat_weight': 0.728874514092429, 'nn_weight': 0.31687785685727277}. Best is trial 0 with value: 0.6274205524205525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 10:33:19,259] Trial 3 finished with value: 0.5491712235133288 and parameters: {'lgb_idx': 75, 'xgb_idx': 48, 'cat_idx': 85, 'nn_idx': 74, 'lgb_weight': 0.6683614651814584, 'xgb_weight': 0.4295297337539553, 'cat_weight': 0.40635174015618913, 'nn_weight': 0.29029642162073444}. Best is trial 0 with value: 0.6274205524205525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best metric: 0.6274205524205525\n",
      "Best hyperparameters and weights: {'lgb_idx': 95, 'xgb_idx': 74, 'cat_idx': 24, 'nn_idx': 87, 'lgb_weight': 0.7650223732630748, 'xgb_weight': 0.41515159469352747, 'cat_weight': 0.728874514092429, 'nn_weight': 0.31687785685727277}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if run_ensemble_trials:\n",
    "    # Create Optuna study and optimize\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=5 , n_jobs =-1)\n",
    "\n",
    "    # Best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(f'Best metric: {best_trial.value}')\n",
    "    print('Best hyperparameters and weights:', best_trial.params)\n",
    "    trials = study.trials\n",
    "\n",
    "    # Extract trial data\n",
    "    data = {\n",
    "        'trial_number': [trial.number for trial in trials],\n",
    "        'value': [trial.value for trial in trials],\n",
    "        'params': [trial.params for trial in trials],\n",
    "        'datetime_start': [trial.datetime_start for trial in trials],\n",
    "        'datetime_complete': [trial.datetime_complete for trial in trials],\n",
    "        'f1': [trial.user_attrs.get('f1', None) for trial in trials],\n",
    "        'accuracy': [trial.user_attrs.get('accuracy', None) for trial in trials],\n",
    "        'roc': [trial.user_attrs.get('roc', None) for trial in trials],\n",
    "        'recall': [trial.user_attrs.get('recall', None) for trial in trials],\n",
    "        'precision': [trial.user_attrs.get('precision', None) for trial in trials]\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    ensemble_results_df = pd.DataFrame(data)\n",
    "    \n",
    "else:\n",
    "    ensemble_results_df = pd.read_csv(r\"../data/processed/ensemble_study.csv\")\n",
    "    ensemble_results_df = ensemble_results_df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         0\n",
       "value                                                         0.627421\n",
       "params               {'lgb_idx': 95, 'xgb_idx': 74, 'cat_idx': 24, ...\n",
       "datetime_start                              2024-08-29 10:31:56.540584\n",
       "datetime_complete                           2024-08-29 10:33:18.459210\n",
       "f1                                                            0.598753\n",
       "accuracy                                                      0.771327\n",
       "roc                                                           0.830314\n",
       "recall                                                        0.642857\n",
       "precision                                                     0.560311\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest weighted recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['value'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         0\n",
       "value                                                         0.627421\n",
       "params               {'lgb_idx': 95, 'xgb_idx': 74, 'cat_idx': 24, ...\n",
       "datetime_start                              2024-08-29 10:31:56.540584\n",
       "datetime_complete                           2024-08-29 10:33:18.459210\n",
       "f1                                                            0.598753\n",
       "accuracy                                                      0.771327\n",
       "roc                                                           0.830314\n",
       "recall                                                        0.642857\n",
       "precision                                                     0.560311\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['recall'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         1\n",
       "value                                                         0.453042\n",
       "params               {'lgb_idx': 34, 'xgb_idx': 4, 'cat_idx': 79, '...\n",
       "datetime_start                              2024-08-29 10:31:56.543494\n",
       "datetime_complete                           2024-08-29 10:32:52.130023\n",
       "f1                                                            0.515068\n",
       "accuracy                                                      0.790284\n",
       "roc                                                            0.83202\n",
       "recall                                                        0.419643\n",
       "precision                                                     0.666667\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest precision\n",
    "ensemble_results_df.iloc[ensemble_results_df['precision'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - AUC: 0.7633 - loss: 0.5030 - val_AUC: 0.8357 - val_loss: 0.4270\n",
      "Epoch 2/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8274 - loss: 0.4392 - val_AUC: 0.8384 - val_loss: 0.4263\n",
      "Epoch 3/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8564 - loss: 0.4058 - val_AUC: 0.8357 - val_loss: 0.4279\n",
      "Epoch 4/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8448 - loss: 0.4235 - val_AUC: 0.8382 - val_loss: 0.4274\n",
      "Epoch 5/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8574 - loss: 0.4042 - val_AUC: 0.8374 - val_loss: 0.4258\n",
      "Epoch 6/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8547 - loss: 0.4083 - val_AUC: 0.8339 - val_loss: 0.4295\n",
      "Epoch 7/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8638 - loss: 0.3958 - val_AUC: 0.8351 - val_loss: 0.4281\n",
      "Epoch 8/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8660 - loss: 0.3900 - val_AUC: 0.8356 - val_loss: 0.4265\n",
      "Epoch 9/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8714 - loss: 0.3878 - val_AUC: 0.8334 - val_loss: 0.4282\n",
      "Epoch 10/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8797 - loss: 0.3763 - val_AUC: 0.8321 - val_loss: 0.4301\n",
      "Epoch 11/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8747 - loss: 0.3798 - val_AUC: 0.8331 - val_loss: 0.4290\n",
      "Epoch 12/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8794 - loss: 0.3724 - val_AUC: 0.8345 - val_loss: 0.4323\n",
      "Epoch 13/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8811 - loss: 0.3752 - val_AUC: 0.8319 - val_loss: 0.4333\n",
      "Epoch 14/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8729 - loss: 0.3856 - val_AUC: 0.8343 - val_loss: 0.4309\n",
      "Epoch 15/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8844 - loss: 0.3695 - val_AUC: 0.8305 - val_loss: 0.4336\n",
      "Epoch 16/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8845 - loss: 0.3699 - val_AUC: 0.8310 - val_loss: 0.4338\n",
      "Epoch 17/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8791 - loss: 0.3798 - val_AUC: 0.8294 - val_loss: 0.4382\n",
      "Epoch 18/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8872 - loss: 0.3656 - val_AUC: 0.8291 - val_loss: 0.4366\n",
      "Epoch 19/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8928 - loss: 0.3465 - val_AUC: 0.8288 - val_loss: 0.4363\n",
      "Epoch 20/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8883 - loss: 0.3658 - val_AUC: 0.8272 - val_loss: 0.4421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x287dd6bd2d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = create_nn_model(clean_hyperparameters(nn_featured_study.iloc[87].to_dict()),input_shape=transformed_featured_train_set.drop(columns='Churn').shape[1])\n",
    "ann_model.fit(transformed_featured_final_train_set.drop(columns='Churn'),transformed_featured_final_train_set['Churn'],epochs=20,validation_data=(transformed_featured_test_set.drop(columns='Churn'),transformed_featured_test_set['Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "roc_auc score is:- 0.8271686743869421\n",
      "recall score is :- 0.6577540106951871\n",
      "precision score is:- 0.5747663551401869\n"
     ]
    }
   ],
   "source": [
    "#let's see final model's performance\n",
    "preds = ann_model.predict(transformed_featured_test_set.drop(columns='Churn'))\n",
    "print('roc_auc score is:-',roc_auc_score(transformed_featured_test_set['Churn'],preds))\n",
    "preds_digits = [1 if pred >= 0.4 else 0 for pred in preds]\n",
    "print('recall score is :-',recall_score(transformed_featured_test_set['Churn'],preds_digits))\n",
    "print('precision score is:-',precision_score(transformed_featured_test_set['Churn'],preds_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
