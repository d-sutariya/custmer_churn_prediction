{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,f1_score,precision_score\n",
    "from optimization.optimize_ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_featured_train_set = pd.read_csv(r\"../data/processed/transformed_featured_train_set.csv\")\n",
    "transformed_featured_val_set = pd.read_csv(r\"../data/processed/transformed_featured_val_set.csv\")\n",
    "transformed_featured_test_set = pd.read_csv(r\"../data/processed/transformed_featured_test_set.csv\")\n",
    "transformed_featured_final_train_set = pd.read_csv(r\"../data/processed/transformed_featured_final_train_set.csv\")\n",
    "lgb_featured_study = pd.read_csv(r\"../data/processed/lgb_featured_study.csv\")\n",
    "xgb_featured_study = pd.read_csv(r\"../data/processed/xgb_featured_study.csv\")\n",
    "catboost_featured_study = pd.read_csv(r\"../data/processed/catboost_featured_study.csv\")\n",
    "nn_featured_study = pd.read_csv(r\"../data/processed/nn_featured_study.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    X_train, y_train = transformed_featured_train_set.drop('Churn', axis=1), transformed_featured_train_set['Churn']  # Extract training features and labels\n",
    "    X_val, y_val = transformed_featured_val_set.drop('Churn', axis=1), transformed_featured_val_set['Churn']  # Extract validation features and labels\n",
    "    \n",
    "    # Sample indices for hyperparameters from different models\n",
    "    lgb_study = drop_unnessesary_columns(lgb_featured_study.copy())  # Prepare LightGBM study data\n",
    "    xgb_study = drop_unnessesary_columns(xgb_featured_study.copy())  # Prepare XGBoost study data\n",
    "    cat_study = drop_unnessesary_columns(catboost_featured_study.copy())  # Prepare CatBoost study data\n",
    "    nn_study = drop_unnessesary_columns(nn_featured_study.copy())  # Prepare Neural Network study data\n",
    "    \n",
    "    lgb_idx = trial.suggest_int('lgb_idx', 0, len(lgb_study) - 1)  # Sample index for LightGBM hyperparameters\n",
    "    xgb_idx = trial.suggest_int('xgb_idx', 0, len(xgb_study) - 1)  # Sample index for XGBoost hyperparameters\n",
    "    cat_idx = trial.suggest_int('cat_idx', 0, len(cat_study) - 1)  # Sample index for CatBoost hyperparameters\n",
    "    nn_idx = trial.suggest_int('nn_idx', 0, len(nn_study) - 1)  # Sample index for Neural Network hyperparameters\n",
    "    \n",
    "    # Fetch hyperparameters and clean them\n",
    "    lgb_params = clean_hyperparameters(lgb_study.iloc[lgb_idx].to_dict())  # Get LightGBM parameters\n",
    "    xgb_params = clean_hyperparameters(xgb_study.iloc[xgb_idx].to_dict())  # Get XGBoost parameters\n",
    "    cat_params = clean_hyperparameters(cat_study.iloc[cat_idx].to_dict())  # Get CatBoost parameters\n",
    "    nn_params = clean_hyperparameters(nn_study.iloc[nn_idx].to_dict())  # Get Neural Network parameters\n",
    "    \n",
    "    # Set additional fixed hyperparameters\n",
    "    lgb_params['verbose'] = -1  # Silence LightGBM output\n",
    "    xgb_params['verbose'] = 0  # Silence XGBoost output\n",
    "    cat_params['early_stopping_rounds'] = 3000  # Set early stopping rounds for CatBoost\n",
    "    cat_params['iterations'] = 200  # Set number of iterations for CatBoost\n",
    "\n",
    "    # Weights for the voting classifier\n",
    "    lgb_weight = trial.suggest_float('lgb_weight', 0.1, 1.0)  # Suggest weight for LightGBM\n",
    "    xgb_weight = trial.suggest_float('xgb_weight', 0.1, 1.0)  # Suggest weight for XGBoost\n",
    "    cat_weight = trial.suggest_float('cat_weight', 0.1, 1.0)  # Suggest weight for CatBoost\n",
    "    nn_weight = trial.suggest_float('nn_weight', 0.1, 1.0)  # Suggest weight for Neural Network\n",
    "\n",
    "    weights = {\n",
    "        'lgb': lgb_weight,\n",
    "        'xgb': xgb_weight,\n",
    "        'cat': cat_weight,\n",
    "        'nn': nn_weight\n",
    "    }  # Store weights in a dictionary\n",
    "    \n",
    "    #Let’s give these models some workout time. First up, LightGBM. \n",
    "    #It's like the gym but for data—let’s see if it can lift those predictions high!\n",
    "    \n",
    "    # Train and predict with LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)  # Prepare LightGBM dataset\n",
    "    lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)  # Train LightGBM model\n",
    "    lgb_preds = lgb_model.predict(X_val)  # Predict on validation set with LightGBM\n",
    "    \n",
    "    #Phew, LightGBM is done. Now let’s see if XGBoost can boost our mood... or just our predictions!\"\n",
    "    \n",
    "    # Train and predict with XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)  # Initialize XGBoost model with parameters\n",
    "    xgb_model.fit(X_train, y_train)  # Train XGBoost model\n",
    "    xgb_preds = xgb_model.predict_proba(X_val)[:, 1]  # Predict on validation set with XGBoost and get probabilities\n",
    "\n",
    "    # Train and predict with CatBoost\n",
    "    cat_model = cb.CatBoostClassifier(**cat_params, verbose=0)  # Initialize CatBoost model with parameters\n",
    "    cat_model.fit(X_train, y_train)  # Train CatBoost model\n",
    "    cat_preds = cat_model.predict_proba(X_val)[:, 1]  # Predict on validation set with CatBoost and get probabilities\n",
    "\n",
    "    # Train and predict with Neural Network using TensorFlow/Keras\n",
    "    nn_model = create_nn_model(nn_params, transformed_featured_train_set.shape[1] - 1)  # Create Neural Network model\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=int(nn_params['batch_size']), verbose=0)  # Train Neural Network model\n",
    "    nn_preds = nn_model.predict(transformed_featured_val_set.drop('Churn', axis=1)).ravel()  # Predict on validation set with Neural Network\n",
    "\n",
    "    # Combine predictions using weighted soft voting\n",
    "    predictions = {\n",
    "        'lgb': lgb_preds,\n",
    "        'xgb': xgb_preds,\n",
    "        'cat': cat_preds,\n",
    "        'nn': nn_preds\n",
    "    }  # Store predictions in a dictionary\n",
    "    combined_preds = weighted_voting(predictions, weights)  # Perform weighted voting to combine predictions\n",
    "    preds_digits = [1 if pred >= 0.4 else 0 for pred in combined_preds]  # Convert probabilities to binary predictions with a threshold of 0.4\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_val, combined_preds)  # Calculate ROC AUC score\n",
    "    f1 = f1_score(y_val, preds_digits)  # Calculate F1 score\n",
    "    recall = recall_score(y_val, preds_digits)  # Calculate recall score\n",
    "    accuracy = accuracy_score(y_val, preds_digits)  # Calculate accuracy score\n",
    "    weighted_recall = 0.65 * recall + 0.35 * f1  # Calculate weighted recall combining recall and F1 score\n",
    "    prec = precision_score(y_val, preds_digits)  # Calculate precision score\n",
    "    \n",
    "    # Store metrics as trial user attributes\n",
    "    trial.set_user_attr('roc', roc_auc)  # Store ROC AUC score in the study\n",
    "    trial.set_user_attr('f1', f1)  # Store F1 score in the study object\n",
    "    trial.set_user_attr('accuracy', accuracy)  # Store accuracy score\n",
    "    trial.set_user_attr('recall', recall)  # Store recall score\n",
    "    trial.set_user_attr('precision', prec)  # Store precision score\n",
    "    \n",
    "    return weighted_recall  # Return weighted recall as the objective value for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ensemble_trials = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 09:03:20,642] A new study created in memory with name: no-name-166969c0-5793-4e49-9d27-10c4fa159205\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 09:04:39,669] Trial 3 finished with value: 0.5786922703478554 and parameters: {'lgb_idx': 83, 'xgb_idx': 71, 'cat_idx': 17, 'nn_idx': 47, 'lgb_weight': 0.9203079150266962, 'xgb_weight': 0.5512132048293996, 'cat_weight': 0.3528436089976743, 'nn_weight': 0.4561744578200917}. Best is trial 3 with value: 0.5786922703478554.\n",
      "[I 2024-08-29 09:04:39,710] Trial 4 finished with value: 0.54270586492891 and parameters: {'lgb_idx': 85, 'xgb_idx': 6, 'cat_idx': 70, 'nn_idx': 22, 'lgb_weight': 0.29580315845167665, 'xgb_weight': 0.7512250283981811, 'cat_weight': 0.588684365372811, 'nn_weight': 0.8407556198551432}. Best is trial 3 with value: 0.5786922703478554.\n",
      "[I 2024-08-29 09:04:39,880] Trial 0 finished with value: 0.6007034632034631 and parameters: {'lgb_idx': 90, 'xgb_idx': 25, 'cat_idx': 60, 'nn_idx': 40, 'lgb_weight': 0.9641079816025739, 'xgb_weight': 0.43383190908494507, 'cat_weight': 0.4191301008310486, 'nn_weight': 0.819552639978684}. Best is trial 0 with value: 0.6007034632034631.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 09:04:47,836] Trial 2 finished with value: 0.5631001170960188 and parameters: {'lgb_idx': 73, 'xgb_idx': 59, 'cat_idx': 88, 'nn_idx': 86, 'lgb_weight': 0.22688645252407963, 'xgb_weight': 0.154703130836274, 'cat_weight': 0.468488194104861, 'nn_weight': 0.9977956230814264}. Best is trial 0 with value: 0.6007034632034631.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-29 09:04:56,312] Trial 1 finished with value: 0.6047973825291706 and parameters: {'lgb_idx': 78, 'xgb_idx': 36, 'cat_idx': 93, 'nn_idx': 40, 'lgb_weight': 0.7214605459161612, 'xgb_weight': 0.7072014936115618, 'cat_weight': 0.6044746694563032, 'nn_weight': 0.39285572034959515}. Best is trial 1 with value: 0.6047973825291706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best metric: 0.6047973825291706\n",
      "Best hyperparameters and weights: {'lgb_idx': 78, 'xgb_idx': 36, 'cat_idx': 93, 'nn_idx': 40, 'lgb_weight': 0.7214605459161612, 'xgb_weight': 0.7072014936115618, 'cat_weight': 0.6044746694563032, 'nn_weight': 0.39285572034959515}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if run_ensemble_trials:\n",
    "    # Create Optuna study and optimize\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=5 , n_jobs =-1)\n",
    "\n",
    "    # Best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(f'Best metric: {best_trial.value}')\n",
    "    print('Best hyperparameters and weights:', best_trial.params)\n",
    "    trials = study.trials\n",
    "\n",
    "    # Extract trial data\n",
    "    data = {\n",
    "        'trial_number': [trial.number for trial in trials],\n",
    "        'value': [trial.value for trial in trials],\n",
    "        'params': [trial.params for trial in trials],\n",
    "        'datetime_start': [trial.datetime_start for trial in trials],\n",
    "        'datetime_complete': [trial.datetime_complete for trial in trials],\n",
    "        'f1': [trial.user_attrs.get('f1', None) for trial in trials],\n",
    "        'accuracy': [trial.user_attrs.get('accuracy', None) for trial in trials],\n",
    "        'roc': [trial.user_attrs.get('roc', None) for trial in trials],\n",
    "        'recall': [trial.user_attrs.get('recall', None) for trial in trials],\n",
    "        'precision': [trial.user_attrs.get('precision', None) for trial in trials]\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    ensemble_results_df = pd.DataFrame(data)\n",
    "    \n",
    "else:\n",
    "    ensemble_results_df = pd.read_csv(r\"../data/processed/ensemble_study.csv\")\n",
    "    ensemble_results_df = ensemble_results_df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         1\n",
       "value                                                         0.604797\n",
       "params               {'lgb_idx': 78, 'xgb_idx': 36, 'cat_idx': 93, ...\n",
       "datetime_start                              2024-08-29 09:03:20.679105\n",
       "datetime_complete                           2024-08-29 09:04:56.311433\n",
       "f1                                                            0.600442\n",
       "accuracy                                                      0.785545\n",
       "roc                                                           0.833842\n",
       "recall                                                        0.607143\n",
       "precision                                                     0.593886\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest weighted recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['value'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         0\n",
       "value                                                         0.600703\n",
       "params               {'lgb_idx': 90, 'xgb_idx': 25, 'cat_idx': 60, ...\n",
       "datetime_start                              2024-08-29 09:03:20.672777\n",
       "datetime_complete                           2024-08-29 09:04:39.875382\n",
       "f1                                                            0.588745\n",
       "accuracy                                                      0.774882\n",
       "roc                                                           0.833129\n",
       "recall                                                        0.607143\n",
       "precision                                                     0.571429\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['recall'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                         3\n",
       "value                                                         0.578692\n",
       "params               {'lgb_idx': 83, 'xgb_idx': 71, 'cat_idx': 17, ...\n",
       "datetime_start                              2024-08-29 09:03:20.690206\n",
       "datetime_complete                           2024-08-29 09:04:39.669298\n",
       "f1                                                            0.600473\n",
       "accuracy                                                      0.799763\n",
       "roc                                                           0.837414\n",
       "recall                                                        0.566964\n",
       "precision                                                     0.638191\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest precision\n",
    "ensemble_results_df.iloc[ensemble_results_df['precision'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - AUC: 0.5185 - loss: 55.7802 - val_AUC: 0.6178 - val_loss: 1.4507\n",
      "Epoch 2/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - AUC: 0.5035 - loss: 25.2308 - val_AUC: 0.5850 - val_loss: 1.4552\n",
      "Epoch 3/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.5247 - loss: 15.1781 - val_AUC: 0.6264 - val_loss: 0.7400\n",
      "Epoch 4/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.5039 - loss: 9.4261 - val_AUC: 0.6355 - val_loss: 0.6090\n",
      "Epoch 5/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.5157 - loss: 5.7865 - val_AUC: 0.6906 - val_loss: 0.5487\n",
      "Epoch 6/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.5320 - loss: 3.8098 - val_AUC: 0.7501 - val_loss: 0.6265\n",
      "Epoch 7/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.5218 - loss: 2.3857 - val_AUC: 0.6555 - val_loss: 0.6458\n",
      "Epoch 8/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.5276 - loss: 1.5796 - val_AUC: 0.7100 - val_loss: 0.6602\n",
      "Epoch 9/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - AUC: 0.5487 - loss: 1.0837 - val_AUC: 0.6852 - val_loss: 0.6545\n",
      "Epoch 10/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.5569 - loss: 0.8787 - val_AUC: 0.7246 - val_loss: 0.6420\n",
      "Epoch 11/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - AUC: 0.5389 - loss: 0.8588 - val_AUC: 0.7295 - val_loss: 0.6391\n",
      "Epoch 12/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.5658 - loss: 0.7142 - val_AUC: 0.7585 - val_loss: 0.6161\n",
      "Epoch 13/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - AUC: 0.5729 - loss: 0.6746 - val_AUC: 0.7548 - val_loss: 0.6139\n",
      "Epoch 14/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.5969 - loss: 0.6788 - val_AUC: 0.7743 - val_loss: 0.5989\n",
      "Epoch 15/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - AUC: 0.5999 - loss: 0.6837 - val_AUC: 0.7734 - val_loss: 0.5712\n",
      "Epoch 16/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - AUC: 0.6231 - loss: 0.6148 - val_AUC: 0.7805 - val_loss: 0.5656\n",
      "Epoch 17/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.6387 - loss: 0.6256 - val_AUC: 0.7728 - val_loss: 0.5418\n",
      "Epoch 18/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.6841 - loss: 0.5553 - val_AUC: 0.7547 - val_loss: 0.5487\n",
      "Epoch 19/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - AUC: 0.6781 - loss: 0.5585 - val_AUC: 0.7710 - val_loss: 0.5250\n",
      "Epoch 20/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - AUC: 0.7101 - loss: 0.5440 - val_AUC: 0.7850 - val_loss: 0.5158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1441c7b3c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = create_nn_model(clean_hyperparameters(nn_featured_study.iloc[87].to_dict()),input_shape=transformed_featured_train_set.drop(columns='Churn').shape[1])\n",
    "ann_model.fit(transformed_featured_final_train_set.drop(columns='Churn'),transformed_featured_final_train_set['Churn'],epochs=20,validation_data=(transformed_featured_test_set.drop(columns='Churn'),transformed_featured_test_set['Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "roc_auc score is:- 0.79433507099927\n",
      "recall score is :- 0.0\n",
      "precision score is:- 0.0\n"
     ]
    }
   ],
   "source": [
    "#let's see final model's performance\n",
    "preds = ann_model.predict(transformed_featured_test_set.drop(columns='Churn'))\n",
    "print('roc_auc score is:-',roc_auc_score(transformed_featured_test_set['Churn'],preds))\n",
    "preds_digits = [1 if pred >= 0.4 else 0 for pred in preds]\n",
    "print('recall score is :-',recall_score(transformed_featured_test_set['Churn'],preds_digits))\n",
    "print('precision score is:-',precision_score(transformed_featured_test_set['Churn'],preds_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
