{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,f1_score,precision_score\n",
    "from optimization.ensemble_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_featured_train_set = pd.read_csv(r\"../data/processed/transformed_featured_train_set.csv\")\n",
    "transformed_featured_val_set = pd.read_csv(r\"../data/processed/transformed_featured_val_set.csv\")\n",
    "transformed_featured_test_set = pd.read_csv(r\"../data/processed/transformed_featured_test_set.csv\")\n",
    "transformed_featured_final_train_set = pd.read_csv(r\"../data/processed/transformed_featured_final_train_set.csv\")\n",
    "lgb_featured_study = pd.read_csv(r\"../reports/optemization-study-reports/lgb_featured_study.csv\")\n",
    "xgb_featured_study = pd.read_csv(r\"../reports/optemization-study-reports/xgb_featured_study.csv\")\n",
    "catboost_featured_study = pd.read_csv(r\"../reports/optemization-study-reports/catboost_featured_study.csv\")\n",
    "nn_featured_study = pd.read_csv(r\"../reports/optemization-study-reports/nn_featured_study.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes several functions that handle tasks such as dropping unnecessary columns from a DataFrame, removing json words from feature naems, generating predictions using multiple models, performing soft and weighted voting for ensemble methods, and cleaning hyperparameters. Additionally, it contains a function to create and compile a neural network model using TensorFlow/Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, refer to the [documentation](../docs/index.html) or explore the [source code](../src/optimization/ensemble_utils.py) of this functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    X_train, y_train = transformed_featured_train_set.drop('Churn', axis=1), transformed_featured_train_set['Churn']  # Extract training features and labels\n",
    "    X_val, y_val = transformed_featured_val_set.drop('Churn', axis=1), transformed_featured_val_set['Churn']  # Extract validation features and labels\n",
    "    \n",
    "    # Sample indices for hyperparameters from different models\n",
    "    lgb_study = drop_unnessesary_columns(lgb_featured_study.copy())  # Prepare LightGBM study data\n",
    "    xgb_study = drop_unnessesary_columns(xgb_featured_study.copy())  # Prepare XGBoost study data\n",
    "    cat_study = drop_unnessesary_columns(catboost_featured_study.copy())  # Prepare CatBoost study data\n",
    "    nn_study = drop_unnessesary_columns(nn_featured_study.copy())  # Prepare Neural Network study data\n",
    "    \n",
    "    lgb_idx = trial.suggest_int('lgb_idx', 0, len(lgb_study) - 1)  # Sample index for LightGBM hyperparameters\n",
    "    xgb_idx = trial.suggest_int('xgb_idx', 0, len(xgb_study) - 1)  # Sample index for XGBoost hyperparameters\n",
    "    cat_idx = trial.suggest_int('cat_idx', 0, len(cat_study) - 1)  # Sample index for CatBoost hyperparameters\n",
    "    nn_idx = trial.suggest_int('nn_idx', 0, len(nn_study) - 1)  # Sample index for Neural Network hyperparameters\n",
    "    \n",
    "    # Fetch hyperparameters and clean them\n",
    "    lgb_params = clean_hyperparameters(lgb_study.iloc[lgb_idx].to_dict())  # Get LightGBM parameters\n",
    "    xgb_params = clean_hyperparameters(xgb_study.iloc[xgb_idx].to_dict())  # Get XGBoost parameters\n",
    "    cat_params = clean_hyperparameters(cat_study.iloc[cat_idx].to_dict())  # Get CatBoost parameters\n",
    "    nn_params = clean_hyperparameters(nn_study.iloc[nn_idx].to_dict())  # Get Neural Network parameters\n",
    "    \n",
    "    # Set additional fixed hyperparameters\n",
    "    lgb_params['verbose'] = -1  # Silence LightGBM output\n",
    "    xgb_params['verbose'] = 0  # Silence XGBoost output\n",
    "    cat_params['early_stopping_rounds'] = 3000  # Set early stopping rounds for CatBoost\n",
    "    cat_params['iterations'] = 200  # Set number of iterations for CatBoost\n",
    "\n",
    "    # Weights for the voting classifier\n",
    "    lgb_weight = trial.suggest_float('lgb_weight', 0.1, 1.0)  # Suggest weight for LightGBM\n",
    "    xgb_weight = trial.suggest_float('xgb_weight', 0.1, 1.0)  # Suggest weight for XGBoost\n",
    "    cat_weight = trial.suggest_float('cat_weight', 0.1, 1.0)  # Suggest weight for CatBoost\n",
    "    nn_weight = trial.suggest_float('nn_weight', 0.1, 1.0)  # Suggest weight for Neural Network\n",
    "\n",
    "    weights = {\n",
    "        'lgb': lgb_weight,\n",
    "        'xgb': xgb_weight,\n",
    "        'cat': cat_weight,\n",
    "        'nn': nn_weight\n",
    "    }  # Store weights in a dictionary\n",
    "    \n",
    "    #Let’s give these models some workout time. First up, LightGBM. \n",
    "    #It's like the gym but for data—let’s see if it can lift those predictions high!\n",
    "    \n",
    "    # Train and predict with LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)  # Prepare LightGBM dataset\n",
    "    lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)  # Train LightGBM model\n",
    "    lgb_preds = lgb_model.predict(X_val)  # Predict on validation set with LightGBM\n",
    "    \n",
    "    #Phew, LightGBM is done. Now let’s see if XGBoost can boost our mood... or just our predictions!\"\n",
    "    \n",
    "    # Train and predict with XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)  # Initialize XGBoost model with parameters\n",
    "    xgb_model.fit(X_train, y_train)  # Train XGBoost model\n",
    "    xgb_preds = xgb_model.predict_proba(X_val)[:, 1]  # Predict on validation set with XGBoost and get probabilities\n",
    "\n",
    "    # Train and predict with CatBoost\n",
    "    cat_model = cb.CatBoostClassifier(**cat_params, verbose=0)  # Initialize CatBoost model with parameters\n",
    "    cat_model.fit(X_train, y_train)  # Train CatBoost model\n",
    "    cat_preds = cat_model.predict_proba(X_val)[:, 1]  # Predict on validation set with CatBoost and get probabilities\n",
    "\n",
    "    # Train and predict with Neural Network using TensorFlow/Keras\n",
    "    nn_model = create_nn_model(nn_params, transformed_featured_train_set.shape[1] - 1)  # Create Neural Network model\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=int(nn_params['batch_size']), verbose=0)  # Train Neural Network model\n",
    "    nn_preds = nn_model.predict(transformed_featured_val_set.drop('Churn', axis=1)).ravel()  # Predict on validation set with Neural Network\n",
    "\n",
    "    # Combine predictions using weighted soft voting\n",
    "    predictions = {\n",
    "        'lgb': lgb_preds,\n",
    "        'xgb': xgb_preds,\n",
    "        'cat': cat_preds,\n",
    "        'nn': nn_preds\n",
    "    }  # Store predictions in a dictionary\n",
    "    combined_preds = weighted_voting(predictions, weights)  # Perform weighted voting to combine predictions\n",
    "    preds_digits = [1 if pred >= 0.4 else 0 for pred in combined_preds]  # Convert probabilities to binary predictions with a threshold of 0.4\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_val, combined_preds)  # Calculate ROC AUC score\n",
    "    f1 = f1_score(y_val, preds_digits)  # Calculate F1 score\n",
    "    recall = recall_score(y_val, preds_digits)  # Calculate recall score\n",
    "    accuracy = accuracy_score(y_val, preds_digits)  # Calculate accuracy score\n",
    "    weighted_recall = 0.65 * recall + 0.35 * f1  # Calculate weighted recall combining recall and F1 score\n",
    "    prec = precision_score(y_val, preds_digits)  # Calculate precision score\n",
    "    \n",
    "    # Store metrics as trial user attributes\n",
    "    trial.set_user_attr('roc', roc_auc)  # Store ROC AUC score in the study\n",
    "    trial.set_user_attr('f1', f1)  # Store F1 score in the study object\n",
    "    trial.set_user_attr('accuracy', accuracy)  # Store accuracy score\n",
    "    trial.set_user_attr('recall', recall)  # Store recall score\n",
    "    trial.set_user_attr('precision', prec)  # Store precision score\n",
    "    \n",
    "    return weighted_recall  # Return weighted recall as the objective value for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ensemble_trials = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_ensemble_trials:\n",
    "    # Create Optuna study and optimize\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=5 , n_jobs =-1)\n",
    "\n",
    "    # Best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(f'Best metric: {best_trial.value}')\n",
    "    print('Best hyperparameters and weights:', best_trial.params)\n",
    "    trials = study.trials\n",
    "\n",
    "    # Extract trial data\n",
    "    data = {\n",
    "        'trial_number': [trial.number for trial in trials],\n",
    "        'value': [trial.value for trial in trials],\n",
    "        'params': [trial.params for trial in trials],\n",
    "        'datetime_start': [trial.datetime_start for trial in trials],\n",
    "        'datetime_complete': [trial.datetime_complete for trial in trials],\n",
    "        'f1': [trial.user_attrs.get('f1', None) for trial in trials],\n",
    "        'accuracy': [trial.user_attrs.get('accuracy', None) for trial in trials],\n",
    "        'roc': [trial.user_attrs.get('roc', None) for trial in trials],\n",
    "        'recall': [trial.user_attrs.get('recall', None) for trial in trials],\n",
    "        'precision': [trial.user_attrs.get('precision', None) for trial in trials]\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    ensemble_results_df = pd.DataFrame(data)\n",
    "    \n",
    "else:\n",
    "    ensemble_results_df = pd.read_csv(r\"../reports/optemization-study-reports/ensemble_study.csv\")\n",
    "    ensemble_results_df = ensemble_results_df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                        22\n",
       "value                                                         0.633703\n",
       "params               {'lgb_idx': 88, 'xgb_idx': 86, 'nn_idx': 40, '...\n",
       "datetime_start                              2024-08-04 06:40:54.247899\n",
       "datetime_complete                           2024-08-04 06:41:05.081042\n",
       "f1                                                            0.616702\n",
       "accuracy                                                      0.787915\n",
       "roc                                                           0.836247\n",
       "recall                                                        0.642857\n",
       "precision                                                     0.592593\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest weighted recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['value'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                        22\n",
       "value                                                         0.633703\n",
       "params               {'lgb_idx': 88, 'xgb_idx': 86, 'nn_idx': 40, '...\n",
       "datetime_start                              2024-08-04 06:40:54.247899\n",
       "datetime_complete                           2024-08-04 06:41:05.081042\n",
       "f1                                                            0.616702\n",
       "accuracy                                                      0.787915\n",
       "roc                                                           0.836247\n",
       "recall                                                        0.642857\n",
       "precision                                                     0.592593\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest recall\n",
    "ensemble_results_df.iloc[ensemble_results_df['recall'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial_number                                                        18\n",
       "value                                                         0.565997\n",
       "params               {'lgb_idx': 54, 'xgb_idx': 17, 'nn_idx': 37, '...\n",
       "datetime_start                              2024-08-04 06:39:18.898603\n",
       "datetime_complete                           2024-08-04 06:39:50.271158\n",
       "f1                                                            0.589074\n",
       "accuracy                                                      0.795024\n",
       "roc                                                           0.828571\n",
       "recall                                                        0.553571\n",
       "precision                                                     0.629442\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's performance which has highest precision\n",
    "ensemble_results_df.iloc[ensemble_results_df['precision'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\project\\Customer Churn Related Things\\customer_churn_prediction\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - AUC: 0.7500 - loss: 0.5144 - val_AUC: 0.8399 - val_loss: 0.4210\n",
      "Epoch 2/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8323 - loss: 0.4320 - val_AUC: 0.8408 - val_loss: 0.4215\n",
      "Epoch 3/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8442 - loss: 0.4212 - val_AUC: 0.8391 - val_loss: 0.4242\n",
      "Epoch 4/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8389 - loss: 0.4295 - val_AUC: 0.8389 - val_loss: 0.4225\n",
      "Epoch 5/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8428 - loss: 0.4239 - val_AUC: 0.8357 - val_loss: 0.4272\n",
      "Epoch 6/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8425 - loss: 0.4263 - val_AUC: 0.8347 - val_loss: 0.4298\n",
      "Epoch 7/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8590 - loss: 0.4043 - val_AUC: 0.8358 - val_loss: 0.4262\n",
      "Epoch 8/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8558 - loss: 0.4073 - val_AUC: 0.8339 - val_loss: 0.4287\n",
      "Epoch 9/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8590 - loss: 0.3982 - val_AUC: 0.8348 - val_loss: 0.4311\n",
      "Epoch 10/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8674 - loss: 0.3968 - val_AUC: 0.8364 - val_loss: 0.4249\n",
      "Epoch 11/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8658 - loss: 0.3905 - val_AUC: 0.8326 - val_loss: 0.4335\n",
      "Epoch 12/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8699 - loss: 0.3840 - val_AUC: 0.8349 - val_loss: 0.4275\n",
      "Epoch 13/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8636 - loss: 0.3938 - val_AUC: 0.8336 - val_loss: 0.4283\n",
      "Epoch 14/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8745 - loss: 0.3853 - val_AUC: 0.8313 - val_loss: 0.4317\n",
      "Epoch 15/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8780 - loss: 0.3768 - val_AUC: 0.8291 - val_loss: 0.4356\n",
      "Epoch 16/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.8754 - loss: 0.3782 - val_AUC: 0.8313 - val_loss: 0.4370\n",
      "Epoch 17/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - AUC: 0.8690 - loss: 0.3927 - val_AUC: 0.8315 - val_loss: 0.4344\n",
      "Epoch 18/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.8781 - loss: 0.3788 - val_AUC: 0.8300 - val_loss: 0.4337\n",
      "Epoch 19/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - AUC: 0.8858 - loss: 0.3632 - val_AUC: 0.8269 - val_loss: 0.4385\n",
      "Epoch 20/20\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - AUC: 0.8833 - loss: 0.3706 - val_AUC: 0.8291 - val_loss: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24572c50c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = create_nn_model(clean_hyperparameters(nn_featured_study.iloc[87].to_dict()),input_shape=transformed_featured_train_set.drop(columns='Churn').shape[1])\n",
    "ann_model.fit(transformed_featured_final_train_set.drop(columns='Churn'),transformed_featured_final_train_set['Churn'],epochs=20,validation_data=(transformed_featured_test_set.drop(columns='Churn'),transformed_featured_test_set['Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "roc_auc score is:- 0.829332560270434\n",
      "recall score is :- 0.7192513368983957\n",
      "precision score is:- 0.5639412997903563\n"
     ]
    }
   ],
   "source": [
    "#let's see final model's performance\n",
    "preds = ann_model.predict(transformed_featured_test_set.drop(columns='Churn'))\n",
    "print('roc_auc score is:-',roc_auc_score(transformed_featured_test_set['Churn'],preds))\n",
    "preds_digits = [1 if pred >= 0.4 else 0 for pred in preds]\n",
    "print('recall score is :-',recall_score(transformed_featured_test_set['Churn'],preds_digits))\n",
    "print('precision score is:-',precision_score(transformed_featured_test_set['Churn'],preds_digits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
